{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#EE793 Project\n","##Homomorphic Encryption  \n","\n","### Koshti Akshata Vaibhav 200070034\n","### Sinnarkar Darshan Vishnu 20D070079\n","### Sharvari Ashok Medhe 20D070073\n","\n","Cryptography serves as a critical tool in preventing data leaks. One particularly significant advancement in this field is homomorphic encryption, which allows for computations to be performed on encrypted data. This technology has gained increasing relevance, especially in light of the growing rates of cloud adoption. In this project, we will explore the integration of homomorphic encryption into a facial recognition pipeline using TenSEAL.\n"],"metadata":{"id":"83aDa44YgbH6"}},{"cell_type":"markdown","source":["We will be using Deepface for face recognition.\n","We will encrypt 3 images and we will calculate the squared euclidian distance between the two tensors of these images pairwise and based on the euclidian distance, we will decide if the two images are of same person or not."],"metadata":{"id":"kwcFHSGphIJX"}},{"cell_type":"code","source":["#!pip install tenseal\n","#!pip install deepface"],"metadata":{"id":"vy4HAVRmSDIg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Ox0WTWYf18d","executionInfo":{"status":"ok","timestamp":1715799243059,"user_tz":-330,"elapsed":3777,"user":{"displayName":"Darshan Sinnarkar","userId":"06187579543314693790"}},"outputId":"f4e42dfe-eb77-4dd8-e04c-afbbc441a8bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u4ae26tbQ4UX"},"outputs":[],"source":["import tenseal as ts\n","from deepface import DeepFace\n","import base64\n","from PIL import Image"]},{"cell_type":"markdown","source":["Loading, displaying of the images:"],"metadata":{"id":"ShQbxcGNsqWR"}},{"cell_type":"code","source":["img1_path = \"/content/drive/MyDrive/EE793/img1.jpg\"\n","img2_path = \"/content/drive/MyDrive/EE793/img2.jpg\"\n","img3_path = \"/content/drive/MyDrive/EE793/img3.jpg\"\n","\n","\n","image1 = Image.open(img1_path)\n","image2 = Image.open(img2_path)\n","image3 = Image.open(img3_path)\n","\n","# Assuming all images have the same dimensions\n","total_width = image1.width + image2.width + image3.width\n","max_height = max(image1.height, image2.height, image3.height)\n","\n","composite_image = Image.new('RGB', (total_width, max_height))\n","composite_image.paste(image1, (0, 0))\n","composite_image.paste(image2, (image1.width, 0))\n","composite_image.paste(image3, (image1.width + image2.width, 0))\n","\n","# Save the composite image to a file\n","composite_image.save('/content/composite_image.jpg')\n","\n","# Display the saved image file\n","composite_image_path = '/content/composite_image.jpg'\n","Image.open(composite_image_path)\n"],"metadata":{"id":"rWpMYuYPTwvm","colab":{"base_uri":"https://localhost:8080/","height":643,"output_embedded_package_id":"1ivOjZR_yWTi3qHCVVyNUZ0XU-4sQQSQM"},"executionInfo":{"status":"ok","timestamp":1715800466863,"user_tz":-330,"elapsed":26205,"user":{"displayName":"Darshan Sinnarkar","userId":"06187579543314693790"}},"outputId":"3300a1c2-d4ff-4d7b-e540-4ab74ae8718b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["We will calculate facial embeddings for two images using the FaceNet model provided by the DeepFace library. Here's a brief explanation:\n","\n","\n","DeepFace.represent(img1_path, model_name='Facenet'): This function call extracts facial embeddings from the image located at img1_path using the FaceNet model. It returns a list containing a dictionary with information about the face in the image, including the embedding vector. By accessing [0]['embedding'], we retrieve the embedding vector associated with the face detected in the image."],"metadata":{"id":"8FgxQqPHs0pv"}},{"cell_type":"code","source":["img1_embedding = DeepFace.represent(img1_path, model_name = 'Facenet')[0]['embedding']\n","img2_embedding = DeepFace.represent(img2_path, model_name = 'Facenet')[0]['embedding']\n","img3_embedding = DeepFace.represent(img3_path, model_name = 'Facenet')[0]['embedding']"],"metadata":{"id":"v3SscFpsTzHn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Defining two functions for writing and reading data to/from a file. Here's a brief explanation:\n","\n","1. `write_data(file_name, data)`: This function takes a file name and data as input. If the data is of type bytes, it encodes it to base64 format using `base64.b64encode()`, then writes the encoded data to the specified file in binary mode ('wb').\n","\n","2. `read_data(file_name)`: This function reads data from the specified file in binary mode ('rb'). It then decodes the data from base64 format to bytes using `base64.b64decode()` and returns the decoded bytes.\n","\n","Overall, these functions facilitate the encoding of data to base64 before writing to a file and decoding from base64 after reading from a file, ensuring compatibility and integrity of the data."],"metadata":{"id":"x6C6gy5ZkXW0"}},{"cell_type":"code","source":["def write_data(file_name, data):\n","    if type(data) == bytes:\n","        #bytes to base64\n","        data = base64.b64encode(data)\n","\n","    with open(file_name, 'wb') as f:\n","        f.write(data)\n","\n","def read_data(file_name):\n","    with open(file_name, 'rb') as f:\n","        data = f.read()\n","    #base64 to bytes\n","    return base64.b64decode(data)"],"metadata":{"id":"YnTA2i-TSRrG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Below code segment initializes a cryptographic context for homomorphic encryption using the CKKS scheme (Cheon-Kim-Kim-Song), a popular choice for practical implementations due to its ability to handle approximate computations on real-valued data. Here's a breakdown of each line:\n","\n","1. `context = ts.context(ts.SCHEME_TYPE.CKKS, poly_modulus_degree = 8192, coeff_mod_bit_sizes = [60, 40, 40, 60])`: This line creates a context object for the CKKS scheme with the following parameters:\n","   - `poly_modulus_degree = 8192`: Specifies the degree of the polynomial modulus, which determines the size of the ciphertext space. A larger degree generally allows for higher precision but increases computational complexity.\n","   - `coeff_mod_bit_sizes = [60, 40, 40, 60]`: Defines the bit sizes for the coefficient modulus. The coefficient modulus is a set of prime numbers that control the noise growth during homomorphic operations. The sizes specified here indicate the bit lengths of these primes, with decreasing values indicating a trade-off between precision and security.\n","\n","2. `context.generate_galois_keys()`: This line generates Galois keys, which are necessary for performing certain homomorphic operations like rotations on encrypted data. These keys allow the homomorphic encryption system to operate efficiently on encrypted data in a way that preserves the underlying mathematical operations.\n","\n","3. `context.global_scale = 2**40`: Sets the global scale parameter, which determines the scaling factor used in encoding and decoding plaintext values. Scaling is crucial for managing the precision of computations in homomorphic encryption. By setting the global scale, you establish a reference point for the numerical range of plaintext values, ensuring that operations remain within a manageable range. In this case, the global scale is set to \\(2^{40}\\), which means that plaintext values will be scaled by \\(2^{40}\\) during encoding and decoding operations."],"metadata":{"id":"e39oNEq7tJfn"}},{"cell_type":"code","source":["context = ts.context(ts.SCHEME_TYPE.CKKS, poly_modulus_degree = 8192, coeff_mod_bit_sizes = [60, 40, 40, 60])\n","context.generate_galois_keys()\n","context.global_scale = 2**40"],"metadata":{"id":"SMg0D7C9SN4T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This code segment involves serialization and storage of cryptographic context objects for the purpose of separating secret and public components. Here's a concise explanation:\n","\n","1. `secret_context = context.serialize(save_secret_key=True)`: This line serializes the cryptographic context object `context`, saving the secret key along with other parameters. The serialized context, which includes the secret key, is then stored in a file named 'secret.txt' using the `write_data` function.\n","\n","2. `context.make_context_public()`: This line modifies the original context object by removing the secret key, effectively making it a public context. This operation is often done to ensure that sensitive information (the secret key) is not accidentally leaked or accessed by unauthorized parties.\n","\n","3. `public_context = context.serialize()`: After making the context public, this line serializes the modified context (now lacking the secret key) and stores it in a file named 'public.txt' using the `write_data` function.\n","\n","Overall, this code separates the secret and public components of the cryptographic context, storing them in separate files for appropriate usage and security management."],"metadata":{"id":"xkvPeWE6lABn"}},{"cell_type":"code","source":["secret_context = context.serialize(save_secret_key = True)\n","write_data(file_name='/content/drive/MyDrive/EE793/secret.txt', data = secret_context)\n","\n","context.make_context_public() #drop the secret_key from the context\n","public_context = context.serialize()\n","write_data(file_name='/content/drive/MyDrive/EE793/public.txt', data = public_context)"],"metadata":{"id":"fY94s1BcSUqq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del context, secret_context, public_context"],"metadata":{"id":"9d-KQX8pSZTa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Encryption"],"metadata":{"id":"o1bzUQEBVHPj"}},{"cell_type":"markdown","source":["\n","This code segment loads previously serialized cryptographic context from a file containing the secret key. Then, it encrypts two vectors using the loaded context. After encryption, it serializes the encrypted vectors and writes them to separate files. Here's a concise explanation:\n","\n","1. `context = ts.context_from(secret.txt')`: This line reads the serialized context containing the secret key from the file 'secret.txt' using the `read_data` function and reconstructs the cryptographic context object `context` from it.\n","\n","2. `enc_v1 = ts.ckks_vector(context, img1_embedding)`: This line encrypts the vector `img1_embedding` using the CKKS scheme and the cryptographic context `context`, creating an encrypted vector `enc_v1`.\n","\n","3. `enc_v1_proto = enc_v1.serialize()`: The encrypted vector `enc_v1` is serialized into a binary format, `enc_v1_proto`, suitable for storage or transmission.\n","\n","4. `write_data('enc_v1.txt', enc_v1_proto)`: The serialized encrypted vector `enc_v1_proto` is written to a file named 'enc_v1.txt' using the `write_data` function.\n","\n","Overall, this code encrypts two vectors using a loaded cryptographic context with the secret key, serializes the encrypted vectors, and stores them in separate files for later use or transmission."],"metadata":{"id":"q1aqyHPStcz4"}},{"cell_type":"code","source":["context = ts.context_from(read_data('/content/drive/MyDrive/EE793/secret.txt'))\n","\n","enc_v1 = ts.ckks_vector(context, img1_embedding)\n","enc_v2 = ts.ckks_vector(context, img2_embedding)\n","enc_v3 = ts.ckks_vector(context, img3_embedding)\n","\n","enc_v1_proto = enc_v1.serialize()\n","enc_v2_proto = enc_v2.serialize()\n","enc_v3_proto = enc_v3.serialize()\n","\n","write_data('/content/drive/MyDrive/EE793/enc_v1.txt', enc_v1_proto)\n","write_data('/content/drive/MyDrive/EE793/enc_v2.txt', enc_v2_proto)\n","write_data('/content/drive/MyDrive/EE793/enc_v3.txt', enc_v3_proto)"],"metadata":{"id":"gbkDoxHxVI_U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del context, enc_v1, enc_v2, enc_v3, enc_v1_proto, enc_v2_proto, enc_v3_proto"],"metadata":{"id":"brInqdTRViAl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Run the server code before running Decryption code"],"metadata":{"id":"XS0AAxALvPGR"}},{"cell_type":"markdown","source":["##Decryption"],"metadata":{"id":"0v5hgvaMWbHI"}},{"cell_type":"markdown","source":["This code decrypts the euclidian distance files (generated by server) using secret key"],"metadata":{"id":"jRK58d9twHmK"}},{"cell_type":"code","source":["#client has the secret key\n","context = ts.context_from(read_data('/content/drive/MyDrive/EE793/secret.txt'))\n","\n","#load euclidean squared value\n","euclidean_squared_proto_12 = read_data('/content/drive/MyDrive/EE793/euclidean_squared_12.txt')\n","euclidean_squared_12 = ts.lazy_ckks_vector_from(euclidean_squared_proto_12)\n","euclidean_squared_12.link_context(context)\n","\n","#load euclidean squared value\n","euclidean_squared_proto_23 = read_data('/content/drive/MyDrive/EE793/euclidean_squared_23.txt')\n","euclidean_squared_23 = ts.lazy_ckks_vector_from(euclidean_squared_proto_23)\n","euclidean_squared_23.link_context(context)\n","\n","#load euclidean squared value\n","euclidean_squared_proto_13 = read_data('/content/drive/MyDrive/EE793/euclidean_squared_13.txt')\n","euclidean_squared_13 = ts.lazy_ckks_vector_from(euclidean_squared_proto_13)\n","euclidean_squared_13.link_context(context)\n","\n","#decrypt it\n","euclidean_squared_plain = []\n","euclidean_squared_plain.append(euclidean_squared_12.decrypt()[0])\n","euclidean_squared_plain.append(euclidean_squared_23.decrypt()[0])\n","euclidean_squared_plain.append(euclidean_squared_13.decrypt()[0])"],"metadata":{"id":"GAcbaBuWWdy6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Since it is a pre-trained model, the threshold for squared euclidean distance is 100"],"metadata":{"id":"7N9cBivvXVtU"}},{"cell_type":"code","source":["if euclidean_squared_plain[0] < 100:\n","    print('Person 1 & 2 are same')\n","else:\n","    print('Person 1 & 2 are different')\n","\n","if euclidean_squared_plain[1] < 100:\n","    print('Person 2 & 3 are same')\n","else:\n","    print('Person 2 & 3 are different')\n","\n","if euclidean_squared_plain[2] < 100:\n","    print('Person 1 & 3 are same')\n","else:\n","    print('Person 1 & 3 are different')"],"metadata":{"id":"1GFByH2pXSjL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715799326646,"user_tz":-330,"elapsed":7,"user":{"displayName":"Darshan Sinnarkar","userId":"06187579543314693790"}},"outputId":"3c8ab0cd-0030-493f-c1da-07fd6a21677e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Person 1 & 2 are same\n","Person 2 & 3 are different\n","Person 1 & 3 are different\n"]}]},{"cell_type":"code","source":["print(euclidean_squared_plain)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gUKNdVRFeDG1","executionInfo":{"status":"ok","timestamp":1715799326646,"user_tz":-330,"elapsed":4,"user":{"displayName":"Darshan Sinnarkar","userId":"06187579543314693790"}},"outputId":"ab92bfdc-2297-4cf8-d2b8-8900f017030d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[-1.676397113602978e+19, 9.03921698411364e+18, 2.0987992859422786e+19]\n"]}]}]}